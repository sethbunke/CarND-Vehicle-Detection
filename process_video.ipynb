{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T18:37:31.564192Z",
     "start_time": "2017-05-29T18:37:31.533684Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import concurrent\n",
    "from moviepy.editor import VideoFileClip\n",
    "from lesson_functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T18:39:02.443594Z",
     "start_time": "2017-05-29T18:39:02.435915Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_space = 'HLS'  # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 16  # HOG pixels per cell\n",
    "cell_per_block = 2  # HOG cells per block\n",
    "hog_channel = \"ALL\"  # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16)  # Spatial binning dimensions\n",
    "hist_bins = 16  # Number of histogram bins\n",
    "spatial_feat = True  # Spatial features on or off\n",
    "hist_feat = True  # Histogram features on or off\n",
    "hog_feat = True  # HOG features on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T18:39:53.486977Z",
     "start_time": "2017-05-29T18:39:53.475394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_params = OrderedDict([\n",
    "    (64, {\"xy_overlap\": (0.75, 0.75), \"x_start_stop\": (120, 1280-120), \"y_start_stop\": (375, 500)}),\n",
    "    (70, {\"xy_overlap\": (0.75, 0.75), \"x_start_stop\": (60, 1280-60), \"y_start_stop\": (375, 500)}),\n",
    "    (90, {\"xy_overlap\": (0.75, 0.75), \"x_start_stop\": (0, 1280), \"y_start_stop\": (375, 560)}),\n",
    "    (115, {\"xy_overlap\": (0.5, 0.5), \"x_start_stop\": (0, 1280), \"y_start_stop\": (375, 600)}),\n",
    "    (154, {\"xy_overlap\": (0.5, 0.5), \"x_start_stop\": (0, 1280), \"y_start_stop\": (400, 680)}),\n",
    "    (185, {\"xy_overlap\": (0.5, 0.5), \"x_start_stop\": (0, 1280), \"y_start_stop\": (450, 680)}),\n",
    "    (218, {\"xy_overlap\": (0.5, 0.5), \"x_start_stop\": (0, 1280), \"y_start_stop\": (450, 680)}),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickle classifier and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T18:39:19.522034Z",
     "start_time": "2017-05-29T18:39:19.474361Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = \"svc.p\" #\"0.0.6_svc.p\"\n",
    "with open(file_name, \"rb\") as ifile:\n",
    "    svc, X_scaler = pickle.load(ifile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T18:39:46.485286Z",
     "start_time": "2017-05-29T18:39:46.405763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_windowing_and_detection_with_image(arg):\n",
    "    xy_size, param_dict, image = arg[0], arg[1], arg[2]\n",
    "    windows = slide_window_from_bottom(\n",
    "        image, x_start_stop=param_dict[\"x_start_stop\"], y_start_stop=param_dict[\"y_start_stop\"],\n",
    "        xy_window=(xy_size, xy_size), xy_overlap=param_dict[\"xy_overlap\"])\n",
    "\n",
    "    hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space,\n",
    "                                 spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                                 orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                 cell_per_block=cell_per_block,\n",
    "                                 hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                                 hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    return hot_windows\n",
    "\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap  # Iterate through list of bboxes\n",
    "\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1] + 1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0, 0, 255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T18:40:12.843183Z",
     "start_time": "2017-05-29T18:40:12.544934Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VehicleDetection:\n",
    "    def __init__(self, n_smoothing_frames=10, threshold_multiplier=8):\n",
    "        self.boxes_queue = []\n",
    "        self.n_smoothing_frames = n_smoothing_frames\n",
    "        self.base_heat = None\n",
    "        self.threshold_multiplier = threshold_multiplier\n",
    "\n",
    "    def add_boxes_set(self, boxes):\n",
    "        self.boxes_queue.append(boxes)\n",
    "        if len(self.boxes_queue) > self.n_smoothing_frames:\n",
    "            self.boxes_queue = self.boxes_queue[-self.n_smoothing_frames:]\n",
    "\n",
    "    def get_all_queue_boxes(self):\n",
    "        return [box for sublist in self.boxes_queue for box in sublist]\n",
    "\n",
    "    def get_base_heatmap(self, img):\n",
    "        if self.base_heat is None:\n",
    "            self.base_heat = np.zeros_like(img[:, :, 0]).astype(np.float)\n",
    "        return self.base_heat.copy()\n",
    "\n",
    "    def get_threshold(self):\n",
    "        # threshold = len(self.boxes_queue)*self.threshold_multiplier\n",
    "        # threshold = len(self.get_all_queue_boxes())*self.threshold_multiplier\n",
    "        threshold = self.threshold_multiplier\n",
    "        return threshold\n",
    "\n",
    "    def _get_boxes(self, cnv):\n",
    "        boxes = []\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            for new_boxes in executor.map(run_windowing_and_detection_with_image,\n",
    "                                          [(k, v, cnv) for k, v in window_params.items()]):\n",
    "                boxes += new_boxes\n",
    "        return boxes\n",
    "\n",
    "    def run(self, img):\n",
    "        # detect all boxes\n",
    "        cnv = convert_to_float_if_required(img)\n",
    "        boxes = self._get_boxes(cnv)\n",
    "\n",
    "        # add to queue, get all the ones for smoothing\n",
    "        self.add_boxes_set(boxes)\n",
    "        boxes4smoothing = self.get_all_queue_boxes()\n",
    "\n",
    "        # create a heat map for filtering false positives\n",
    "        heat = add_heat(self.get_base_heatmap(img), boxes4smoothing)\n",
    "        heat = apply_threshold(heat, self.get_threshold())\n",
    "        heatmap = np.clip(heat, 0, 255)\n",
    "        # Find final boxes from heatmap using label function\n",
    "        labels = label(heatmap)\n",
    "        img = draw_labeled_bboxes(img, labels)\n",
    "\n",
    "        # img = draw_boxes(img, boxes, color=(0, 0, 255), thick=4)\n",
    "        return img\n",
    "\n",
    "    def run_debug(self, img):\n",
    "        # detect all boxes\n",
    "        cnv = convert_to_float_if_required(img)\n",
    "        boxes = self._get_boxes(cnv)\n",
    "\n",
    "        # add to queue, get all the ones for smoothing\n",
    "        self.add_boxes_set(boxes)\n",
    "        boxes4smoothing = self.get_all_queue_boxes()\n",
    "\n",
    "        # create a heat map for filtering false positives\n",
    "        heat = add_heat(self.get_base_heatmap(img), boxes4smoothing)\n",
    "        heat = apply_threshold(heat, self.get_threshold())\n",
    "        heatmap = np.clip(heat, 0, 255)\n",
    "        # Find final boxes from heatmap using label function\n",
    "        labels = label(heatmap)\n",
    "\n",
    "        # plotting\n",
    "        grid_shape = (2, 2)\n",
    "        figure = plt.figure(figsize=[16, 10])\n",
    "        to_plot = [\n",
    "            ((0, 0), draw_labeled_bboxes(img.copy(), labels), \"Project output\", {}),\n",
    "            ((0, 1), draw_boxes(img.copy(), boxes, color=(0, 0, 255), thick=4), \"Boxes detected this frame\", {}),\n",
    "            ((1, 1), draw_boxes(img.copy(), boxes4smoothing, color=(0, 0, 255), thick=4),\n",
    "             \"Boxes detected last {} frames\".format(self.n_smoothing_frames), {}),\n",
    "            ((1, 0), heatmap, \"Heatmap of boxes detect in last {} frames\".format(self.n_smoothing_frames),\n",
    "             {\"cmap\": \"hot\"})\n",
    "        ]\n",
    "\n",
    "        for pos, data, title, kwargs in to_plot:\n",
    "            ax = plt.subplot2grid(grid_shape, pos)\n",
    "            ax.imshow(data, **kwargs)\n",
    "            ax.set_title(title)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        figimg = self.convert_to_image_smart()\n",
    "        plt.close(figure)\n",
    "        return figimg\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_image_smart():\n",
    "        figure = plt.gcf()\n",
    "\n",
    "        # remove anti aliasing, might not be necessary\n",
    "        matplotlib.rcParams['text.antialiased'] = False\n",
    "        for ax in figure.axes:\n",
    "            plt.setp(\n",
    "                [ax.get_xticklines() + ax.get_yticklines() + ax.get_xgridlines() + ax.get_ygridlines()],\n",
    "                antialiased=False)\n",
    "\n",
    "        # draw the figure\n",
    "        figure.canvas.draw()\n",
    "\n",
    "        # Now we can save it to a numpy array.\n",
    "        data = np.fromstring(figure.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        return data.reshape(figure.canvas.get_width_height()[::-1] + (3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-29T18:43:09.049584Z",
     "start_time": "2017-05-29T18:43:09.045224Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./0.0.6_frames_50_thresh_230_project_video.mp4\n",
      "[MoviePy] Writing video ./0.0.6_frames_50_thresh_230_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [42:09<00:02,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./0.0.6_frames_50_thresh_230_project_video.mp4 \n",
      "\n",
      "Output video: 0.0.6_frames_50_thresh_230_project_video.mp4\n"
     ]
    }
   ],
   "source": [
    "video_name = \"project_video.mp4\"\n",
    "output_directory = \".\"\n",
    "\n",
    "n_frames = 50\n",
    "thresh = 230\n",
    "vd = VehicleDetection(n_smoothing_frames=n_frames, threshold_multiplier=thresh)\n",
    "out_fn = \"0.0.6_frames_{}_thresh_{}_{}\".format(n_frames, thresh, video_name)\n",
    "\n",
    "clip = VideoFileClip(\"./\" + video_name)\n",
    "project_clip = clip.fl_image(vd.run)\n",
    "project_clip.write_videofile(join(output_directory, out_fn), audio=False)\n",
    "print(\"Output video: {}\".format(out_fn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
